{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5d90f9a-fddf-46e6-a873-3c9b5eb12906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "from scipy.stats.contingency import crosstab\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ee90486-70f6-4315-848c-231d45f970f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "#results_all = pd.read_excel(\"results all Nov24/test_model_all_summary.xlsx\")\n",
    "results_all_original = pd.read_excel(\"results all Nov24/test_model_all_summary.xlsx\")\n",
    "results_litneg_original = pd.read_excel(\"results all Nov24/test_model_litneg_summary.xlsx\")\n",
    "results_all_M = pd.read_excel(\"results Nov25/test_model_Nov25_all_summary.xlsx\")\n",
    "results_human = pd.read_excel(\"results all Nov24/test_model_human_summary.xlsx\")[:1146]\n",
    "results_litneg_M = pd.read_excel(\"results Nov25/test_model_Nov25_litneg_summary.xlsx\")\n",
    "results_test = pd.read_excel(\"results Nov25/test_model_Nov25_test_summary.xlsx\")[:1146]\n",
    "\n",
    "data_all = pd.read_excel(\"Datasets/Fig-QA Dataset calc.xlsx\")\n",
    "data_test = pd.read_excel(\"Datasets/Fig-QA Dataset test calc.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c8737d2-1841-448a-8c57-02aa4077f5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.584621572151631e-33\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "results_pair = results_all_M[['Llama-3-70B-Instruct M1 bin','Llama-3.1-405B-Instruct M1 bin']].dropna()\n",
    "ctab = crosstab(list(results_pair.iloc[:,0]), list(results_pair.iloc[:,1]))[1]\n",
    "print(mcnemar(ctab).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a5947e1a-d580-4eca-9c62-b8dd06412bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not neg vs not intens\n",
      "(-1.346075413602316, 0.17827819686189772)\n",
      "not neg vs antonym neg\n",
      "(1.0186861660131479, 0.3083519823026398)\n",
      "antonym neg vs antonym intens\n",
      "(-5.873488374606067, 4.267189686320674e-09)\n",
      "not intens vs antonym intens\n",
      "(-4.086471882190472, 4.3798253784877834e-05)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntest_name = \"not neg vs antonym neg\"\\ndata1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"neg\"])\\ndata2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"neg\"])\\nresults.append(stat_test(data1, data2, \"chi2\", m))\\n\\ntest_name = \"antonym neg vs antonym intens\"\\ndata1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"neg\"])\\ndata2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"intens\"])\\nresults.append(stat_test(data1, data2, \"chi2\", m))\\n\\ntest_name = \"not intens vs antonym intens\"\\ndata1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"intens\"])\\ndata2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"intens\"])\\nresults.append(stat_test(data1, data2, \"chi2\", m))\\n'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=\"Q total\"\n",
    "\n",
    "test_name = \"not neg vs not intens\"\n",
    "data1 = []\n",
    "data2 = []\n",
    "for m in all_models_test:\n",
    "    data1 += list(results_test[m+\" bin\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"neg\"])\n",
    "    data2 += list(results_test[m+\" bin\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"intens\"])\n",
    "\n",
    "print(test_name)\n",
    "print(proportions_ztest((sum(data1),sum(data2)),(len(data1),len(data2))))\n",
    "    \n",
    "test_name = \"not neg vs antonym neg\"\n",
    "data1 = []\n",
    "data2 = []\n",
    "for m in all_models_test:\n",
    "    data1 += list(results_test[m+\" bin\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"neg\"])\n",
    "    data2 += list(results_test[m+\" bin\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"neg\"])\n",
    "\n",
    "print(test_name)\n",
    "print(proportions_ztest((sum(data1),sum(data2)),(len(data1),len(data2))))\n",
    "    \n",
    "test_name = \"antonym neg vs antonym intens\"\n",
    "data1 = []\n",
    "data2 = []\n",
    "for m in all_models_test:\n",
    "    data1 += list(results_test[m+\" bin\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"neg\"])\n",
    "    data2 += list(results_test[m+\" bin\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"intens\"])\n",
    "\n",
    "print(test_name)\n",
    "print(proportions_ztest((sum(data1),sum(data2)),(len(data1),len(data2))))\n",
    "    \n",
    "test_name = \"not intens vs antonym intens\"\n",
    "data1 = []\n",
    "data2 = []\n",
    "for m in all_models_test:\n",
    "    data1 += list(results_test[m+\" bin\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"intens\"])\n",
    "    data2 += list(results_test[m+\" bin\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"intens\"])\n",
    "\n",
    "print(test_name)\n",
    "print(proportions_ztest((sum(data1),sum(data2)),(len(data1),len(data2))))\n",
    "    \n",
    "#results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "\n",
    "'''\n",
    "test_name = \"not neg vs antonym neg\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"neg\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"neg\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "\n",
    "test_name = \"antonym neg vs antonym intens\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"neg\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"intens\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "\n",
    "test_name = \"not intens vs antonym intens\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"intens\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"intens\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c091a01b-a303-47b6-adf9-65bdf5f008a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_test(data1, data2, tst, model):\n",
    "    if tst == \"mcnemar\":\n",
    "        results_pair = pd.DataFrame({\"a\":data1,\"b\":data2}).dropna()\n",
    "        ctab = crosstab(results_pair.iloc[:,0], results_pair.iloc[:,1])[1]\n",
    "    elif tst == \"chi2\":\n",
    "        if len(data1)>len(data2):\n",
    "            data2 += [np.nan]*(len(data1)-len(data2))\n",
    "        elif len(data2)>len(data1):\n",
    "            data1 += [np.nan]*(len(data2)-len(data1))\n",
    "        results_pair = pd.DataFrame({\"a\":data1,\"b\":data2})\n",
    "        ctab = crosstab([\"a\"]*len(list(results_pair.iloc[:,0]))+[\"b\"]*len(list(results_pair.iloc[:,1])), list(results_pair.iloc[:,0])+list(results_pair.iloc[:,1]))[1]\n",
    "    ctab = ctab[:,:2] # remove nans\n",
    "    row = []\n",
    "    row.append(test_name)\n",
    "    row.append(model)\n",
    "    row.append(np.mean([x for x in data1 if not(np.isnan(x))]))\n",
    "    row.append(np.mean([x for x in data2 if not(np.isnan(x))]))\n",
    "    if tst == \"mcnemar\":\n",
    "        row.append(mcnemar(ctab).pvalue)\n",
    "    #elif tst == \"chi2\":\n",
    "    #    row.append(chi2_contingency(ctab)[1])\n",
    "    elif tst == \"chi2\":\n",
    "        data1 = [x for x in data1 if not(np.isnan(x))]\n",
    "        data2 = [x for x in data2 if not(np.isnan(x))]\n",
    "        row.append(proportions_ztest((len(data1),len(data2)),(sum(data1,sum(data2))))[1])\n",
    "    row.append(tst)\n",
    "    row.append(np.nan)\n",
    "    return row\n",
    "    \n",
    "    \n",
    "\n",
    "def ttest(data1, data2):\n",
    "    data1 = [x for x in data1 if not(np.isnan(x))]\n",
    "    data2 = [x for x in data2 if not(np.isnan(x))]\n",
    "    row = []\n",
    "    row.append(test_name)\n",
    "    row.append(m)\n",
    "    row.append(np.mean(data1))\n",
    "    row.append(np.mean(data2))\n",
    "    row.append(ttest_ind(data1,data2).pvalue)\n",
    "    row.append(ttest_ind(data1,data2, alternative=\"less\").pvalue)\n",
    "    row.append(ttest_ind(data1,data2, alternative=\"greater\").pvalue)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a13634f0-35ff-47dc-a5ef-f2b09bd6ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_original = [\"glove add_lem\",\n",
    "                    \"sbert2_long\",\n",
    "                    \"GPT-Neo-1.3B m2\",\n",
    "                    \"Llama2-7B m2\",\n",
    "                    \"Llama2-13B m2\",\n",
    "                    \"Llama2-70B m2\",\n",
    "                    \"Llama2-7B-chat m2\",\n",
    "                    \"Llama2-13B-chat m2\",\n",
    "                    \"Llama-3-70B-Instruct-Turbo m2\",\n",
    "                    \"Llama-3.1-70B-Instruct-Turbo m2\",\n",
    "                    \"Llama-3.1-405B-Instruct-Turbo m2\",\n",
    "                    \"Llama-3.3-70B-Instruct-Turbo m2\",\n",
    "                    \"Llama2-70B mixedprompt\",\n",
    "                    \"Llama2-13B-chat mixedprompt\",\n",
    "                    \"Llama-3.1-70B-Instruct-Turbo mixedprompt\",\n",
    "                    \"Llama-3.1-405B-Instruct-Turbo mixedprompt\",\n",
    "                    \"Llama-3.3-70B-Instruct-Turbo mixedprompt\",\n",
    "                    \"GPT-4o-mini mixedprompt\",\n",
    "                    \"GPT-4o mixedprompt\",\n",
    "                    \"o1-mini mixedprompt\",\n",
    "                   ]\n",
    "all_models_M =     [\"Llama-3-70B-Instruct\",\n",
    "                    \"Llama-3.1-70B-Instruct\",\n",
    "                    \"Llama-3.1-405B-Instruct\",\n",
    "                    \"Llama-3.3-70B-Instruct\",\n",
    "                   ]\n",
    "all_models_test =  [\"Llama3.1-70B-Instruct Q\",\n",
    "                    \"Llama3.1-405B-Instruct Q\",\n",
    "                    \"Llama3.3-70B-Instruct Q\",\n",
    "                    \"gpt-4o-mini Q\",\n",
    "                    \"gpt-4o Q\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90edd77a-1f5a-46c1-8f18-4d42b26db9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd9ce1eb-b77e-4362-97ee-0a06d116e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model vs human \n",
    "test_name = \"model vs human\"\n",
    "for m in all_models_test:\n",
    "\n",
    "    data1 = list(results_test[m+\" bin\"])\n",
    "    data2 = list(results_human[\"bin human\"])\n",
    "    results.append(stat_test(data1, data2, \"mcnemar\", m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ed167f7-2c04-4cef-8c45-660116259910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# met vs sim\n",
    "test_name = \"met vs sim\"\n",
    "for m in all_models_original:\n",
    "    data1 = list(results_all_original[\"bin \"+m][data_all[\"met sim\"]==\"sim\"])\n",
    "    data2 = list(results_all_original[\"bin \"+m][data_all[\"met sim\"]==\"met\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "    \n",
    "for m in all_models_M:\n",
    "    # c (M123)\n",
    "    data1 = list(results_all_M[m+\" M1 bin\"][data_all[\"met sim\"]==\"sim\"]) + list(results_all_M[m+\" M2 bin\"][data_all[\"met sim\"]==\"sim\"]) + list(results_all_M[m+\" M3 bin\"][data_all[\"met sim\"]==\"sim\"])\n",
    "    data2 = list(results_all_M[m+\" M1 bin\"][data_all[\"met sim\"]==\"met\"]) + list(results_all_M[m+\" M2 bin\"][data_all[\"met sim\"]==\"met\"]) + list(results_all_M[m+\" M3 bin\"][data_all[\"met sim\"]==\"met\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" c\"))\n",
    "    # cf (M45)\n",
    "    data1 = list(results_all_M[m+\" M4 bin\"][data_all[\"met sim\"]==\"sim\"]) + list(results_all_M[m+\" M5 bin\"][data_all[\"met sim\"]==\"sim\"])\n",
    "    data2 = list(results_all_M[m+\" M4 bin\"][data_all[\"met sim\"]==\"met\"]) + list(results_all_M[m+\" M5 bin\"][data_all[\"met sim\"]==\"met\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" cf\"))\n",
    "    \n",
    "for m in all_models_test:\n",
    "    data1 = list(results_test[m+\" bin\"][data_test[\"met sim\"]==\"sim\"])\n",
    "    data2 = list(results_test[m+\" bin\"][data_test[\"met sim\"]==\"met\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "    \n",
    "data1 = []\n",
    "data2 = []\n",
    "for m in all_models_test:\n",
    "    data1 += list(results_test[m+\" bin\"][data_test[\"met sim\"]==\"sim\"])\n",
    "    data2 += list(results_test[m+\" bin\"][data_test[\"met sim\"]==\"met\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", \"q_test_total\"))\n",
    "\n",
    "m = \"human\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"met sim\"]==\"sim\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"met sim\"]==\"met\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "827f5daa-17bf-463e-8596-5aaf1e7d100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg vs intens\n",
    "test_name = \"neg vs intens\"\n",
    "for m in all_models_original:\n",
    "    data1 = list(results_all_original[\"bin \"+m][data_all[\"negation\"]==\"neg\"])\n",
    "    data2 = list(results_all_original[\"bin \"+m][data_all[\"negation\"]==\"intens\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "for m in all_models_M:\n",
    "    # c (M123)\n",
    "    data1 = list(results_all_M[m+\" M1 bin\"][data_all[\"negation\"]==\"neg\"]) + list(results_all_M[m+\" M2 bin\"][data_all[\"negation\"]==\"neg\"]) + list(results_all_M[m+\" M3 bin\"][data_all[\"negation\"]==\"neg\"])\n",
    "    data2 = list(results_all_M[m+\" M1 bin\"][data_all[\"negation\"]==\"intens\"]) + list(results_all_M[m+\" M2 bin\"][data_all[\"negation\"]==\"intens\"]) + list(results_all_M[m+\" M3 bin\"][data_all[\"negation\"]==\"intens\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" c\"))\n",
    "    # cf (M45)\n",
    "    data1 = list(results_all_M[m+\" M4 bin\"][data_all[\"negation\"]==\"neg\"]) + list(results_all_M[m+\" M5 bin\"][data_all[\"negation\"]==\"neg\"])\n",
    "    data2 = list(results_all_M[m+\" M4 bin\"][data_all[\"negation\"]==\"intens\"]) + list(results_all_M[m+\" M5 bin\"][data_all[\"negation\"]==\"intens\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" cf\"))\n",
    "for m in all_models_test:\n",
    "    data1 = list(results_test[m+\" bin\"][data_test[\"negation\"]==\"neg\"])\n",
    "    data2 = list(results_test[m+\" bin\"][data_test[\"negation\"]==\"intens\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "\n",
    "data1 = []\n",
    "data2 = []\n",
    "for m in all_models_test:\n",
    "    data1 += list(results_test[m+\" bin\"][data_test[\"negation\"]==\"neg\"])\n",
    "    data2 += list(results_test[m+\" bin\"][data_test[\"negation\"]==\"intens\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", \"q_test_total\"))\n",
    "    \n",
    "m = \"human\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"negation\"]==\"neg\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"negation\"]==\"intens\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d1ddb28-e828-4f71-91de-95021f90b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# past vs pres\n",
    "test_name = \"past vs pres\"\n",
    "for m in all_models_original:\n",
    "    data1 = list(results_all_original[\"bin \"+m][data_all[\"tense\"]==\"Past\"])\n",
    "    data2 = list(results_all_original[\"bin \"+m][data_all[\"tense\"]==\"Pres\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "for m in all_models_M:\n",
    "    # c (M123)\n",
    "    data1 = list(results_all_M[m+\" M1 bin\"][data_all[\"tense\"]==\"Past\"]) + list(results_all_M[m+\" M2 bin\"][data_all[\"tense\"]==\"Past\"]) + list(results_all_M[m+\" M3 bin\"][data_all[\"tense\"]==\"Past\"])\n",
    "    data2 = list(results_all_M[m+\" M1 bin\"][data_all[\"tense\"]==\"Pres\"]) + list(results_all_M[m+\" M2 bin\"][data_all[\"tense\"]==\"Pres\"]) + list(results_all_M[m+\" M3 bin\"][data_all[\"tense\"]==\"Pres\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" c\"))\n",
    "    # cf (M45)\n",
    "    data1 = list(results_all_M[m+\" M4 bin\"][data_all[\"tense\"]==\"Past\"]) + list(results_all_M[m+\" M5 bin\"][data_all[\"tense\"]==\"Past\"])\n",
    "    data2 = list(results_all_M[m+\" M4 bin\"][data_all[\"tense\"]==\"Pres\"]) + list(results_all_M[m+\" M5 bin\"][data_all[\"tense\"]==\"Pres\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" cf\"))\n",
    "for m in all_models_test:\n",
    "    data1 = list(results_test[m+\" bin\"][data_test[\"tense\"]==\"Past\"])\n",
    "    data2 = list(results_test[m+\" bin\"][data_test[\"tense\"]==\"Pres\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "\n",
    "data1 = []\n",
    "data2 = []\n",
    "for m in all_models_test:\n",
    "    data1 += list(results_test[m+\" bin\"][data_test[\"tense\"]==\"Past\"])\n",
    "    data2 += list(results_test[m+\" bin\"][data_test[\"tense\"]==\"Pres\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", \"q_test_total\"))\n",
    "    \n",
    "m = \"human\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"tense\"]==\"Past\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"tense\"]==\"Pres\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "342552af-7915-4241-991a-37b8dc6b6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low vs high concreteness\n",
    "test_name = \"low vs high concreteness\"\n",
    "for m in all_models_original:\n",
    "    data1 = list(results_all_original[\"bin \"+m][data_all[\"concreteness category\"]==\"L\"])\n",
    "    data2 = list(results_all_original[\"bin \"+m][data_all[\"concreteness category\"]==\"H\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "for m in all_models_M:\n",
    "    # c (M123)\n",
    "    data1 = list(results_all_M[m+\" M1 bin\"][data_all[\"concreteness category\"]==\"L\"]) + list(results_all_M[m+\" M2 bin\"][data_all[\"concreteness category\"]==\"L\"]) + list(results_all_M[m+\" M3 bin\"][data_all[\"concreteness category\"]==\"L\"])\n",
    "    data2 = list(results_all_M[m+\" M1 bin\"][data_all[\"concreteness category\"]==\"H\"]) + list(results_all_M[m+\" M2 bin\"][data_all[\"concreteness category\"]==\"h\"]) + list(results_all_M[m+\" M3 bin\"][data_all[\"concreteness category\"]==\"H\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" c\"))\n",
    "    # cf (M45)\n",
    "    data1 = list(results_all_M[m+\" M4 bin\"][data_all[\"concreteness category\"]==\"L\"]) + list(results_all_M[m+\" M5 bin\"][data_all[\"concreteness category\"]==\"L\"])\n",
    "    data2 = list(results_all_M[m+\" M4 bin\"][data_all[\"concreteness category\"]==\"H\"]) + list(results_all_M[m+\" M5 bin\"][data_all[\"concreteness category\"]==\"H\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" cf\"))\n",
    "for m in all_models_test:\n",
    "    data1 = list(results_test[m+\" bin\"][data_test[\"concreteness category\"]==\"L\"])\n",
    "    data2 = list(results_test[m+\" bin\"][data_test[\"concreteness category\"]==\"H\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "    \n",
    "data1 = []\n",
    "data2 = []\n",
    "for m in all_models_test:\n",
    "    data1 += list(results_test[m+\" bin\"][data_test[\"concreteness category\"]==\"L\"])\n",
    "    data2 += list(results_test[m+\" bin\"][data_test[\"concreteness category\"]==\"H\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", \"q_test_total\"))\n",
    "    \n",
    "m = \"human\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"concreteness category\"]==\"L\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"concreteness category\"]==\"H\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bd05ddf-2217-484e-bd67-cbdba5d49ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# midphrase A vs midphrase B\n",
    "\n",
    "for m in [\"Llama-3-70B-Instruct\",\n",
    "          \"Llama-3.1-70B-Instruct\",\n",
    "          \"Llama-3.1-405B-Instruct\",\n",
    "          \"Llama-3.3-70B-Instruct\",\n",
    "                   ]:\n",
    "    mids = (\"M1\",\"M2\",\"M3\",\"M4\",\"M5\",)\n",
    "    for mid1 in mids:\n",
    "        for mid2 in mids:\n",
    "            if int(mid1[-1]) < int(mid2[-1]):\n",
    "                test_name = mid1+\" vs \"+mid2\n",
    "                data1 = list(results_all_M[m+\" \"+mid1+\" bin\"])\n",
    "                data2 = list(results_all_M[m+\" \"+mid2+\" bin\"])\n",
    "                results.append(stat_test(data1, data2, \"mcnemar\", m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3d2f23c-0db4-4330-88a2-598fd53007f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c (M123) vs cf (M45)\n",
    "test_name = \"c vs cf\"\n",
    "for m in [\"Llama-3-70B-Instruct\",\n",
    "          \"Llama-3.1-70B-Instruct\",\n",
    "          \"Llama-3.1-405B-Instruct\",\n",
    "          \"Llama-3.3-70B-Instruct\",\n",
    "         ]:        \n",
    "    data1 = list(results_all_M[m+\" M1 bin\"]) + list(results_all_M[m+\" M2 bin\"]) + list(results_all_M[m+\" M3 bin\"])\n",
    "    data2 = list(results_all_M[m+\" M4 bin\"]) + list(results_all_M[m+\" M5 bin\"])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59b91baa-e628-4da1-be87-c09fa6b9bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg types - human\n",
    "test_name = \"not neg vs not intens\"\n",
    "m = \"human\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"neg\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"intens\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "\n",
    "test_name = \"not neg vs antonym neg\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"neg\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"neg\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "\n",
    "test_name = \"antonym neg vs antonym intens\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"neg\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"intens\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))\n",
    "\n",
    "test_name = \"not intens vs antonym intens\"\n",
    "data1 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"not\"][data_test[\"negation\"]==\"intens\"])\n",
    "data2 = list(results_human[\"bin human\"][data_test[\"paired sim negpair type\"]==\"antonym\"][data_test[\"negation\"]==\"intens\"])\n",
    "results.append(stat_test(data1, data2, \"chi2\", m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a180914e-a74e-4c6c-bbeb-d0fc62d3dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = \"lit vs fig\"\n",
    "for m in all_models_original:\n",
    "    data1 = list(results_litneg_original[\"bin \"+m])\n",
    "    data2 = list(results_all_original[\"bin \"+m][data_all[\"litneg\"]==1])\n",
    "    results.append(stat_test(data1, data2, \"mcnemar\", m))\n",
    "    \n",
    "for m in all_models_M:\n",
    "    # c (M123)\n",
    "    data1 = list(results_litneg_M[m+\" M1 bin\"]) + list(results_litneg_M[m+\" M2 bin\"]) + list(results_litneg_M[m+\" M3 bin\"])\n",
    "    data2 = list(results_all_M[m+\" M1 bin\"][data_all[\"litneg\"]==1]) + list(results_all_M[m+\" M2 bin\"][data_all[\"litneg\"]==1]) + list(results_all_M[m+\" M3 bin\"][data_all[\"litneg\"]==1])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" c\"))\n",
    "    # cf (M45)\n",
    "    data1 = list(results_litneg_M[m+\" M4 bin\"]) + list(results_litneg_M[m+\" M5 bin\"])\n",
    "    data2 = list(results_all_M[m+\" M4 bin\"][data_all[\"litneg\"]==1]) + list(results_all_M[m+\" M5 bin\"][data_all[\"litneg\"]==1])\n",
    "    results.append(stat_test(data1, data2, \"chi2\", m+\" cf\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a832568-abe0-4819-bd80-22c516b81648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "stattest_results = pd.DataFrame(results, columns=[\"test\", \"model\", \"avg1\", \"avg2\", \"pvalue\", \"stattest\", \"\"]) #[\"test\", \"model\", \"avg1\", \"avg2\", \"ttest_2_sided\", \"ttest_1_sided_l\", \"ttest_1_sided_g\"]\n",
    "stattest_results.to_csv(\"Results Nov25/stats_out_z_02-02-26.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00d0c13d-577a-404b-9af6-e66133c35d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>avg1</th>\n",
       "      <th>avg2</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>stattest</th>\n",
       "      <th>group</th>\n",
       "      <th>p_corrected</th>\n",
       "      <th>corrected test</th>\n",
       "      <th>corrected model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model vs human</td>\n",
       "      <td>Llama3.1-70B-Instruct Q</td>\n",
       "      <td>0.913613</td>\n",
       "      <td>0.945852</td>\n",
       "      <td>1.558171e-03</td>\n",
       "      <td>mcnemar</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126092</td>\n",
       "      <td>5q</td>\n",
       "      <td>Llama2-70B mixedprompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model vs human</td>\n",
       "      <td>Llama3.1-405B-Instruct Q</td>\n",
       "      <td>0.931937</td>\n",
       "      <td>0.945852</td>\n",
       "      <td>1.742054e-01</td>\n",
       "      <td>mcnemar</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739841</td>\n",
       "      <td>5q</td>\n",
       "      <td>Llama2-13B-chat mixedprompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model vs human</td>\n",
       "      <td>Llama3.3-70B-Instruct Q</td>\n",
       "      <td>0.920593</td>\n",
       "      <td>0.945852</td>\n",
       "      <td>1.127581e-02</td>\n",
       "      <td>mcnemar</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716996</td>\n",
       "      <td>5q</td>\n",
       "      <td>Llama-3.1-70B-Instruct-Turbo mixedprompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model vs human</td>\n",
       "      <td>gpt-4o-mini Q</td>\n",
       "      <td>0.880454</td>\n",
       "      <td>0.945852</td>\n",
       "      <td>2.220000e-09</td>\n",
       "      <td>mcnemar</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126092</td>\n",
       "      <td>5q</td>\n",
       "      <td>Llama-3.1-405B-Instruct-Turbo mixedprompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model vs human</td>\n",
       "      <td>gpt-4o Q</td>\n",
       "      <td>0.949389</td>\n",
       "      <td>0.945852</td>\n",
       "      <td>7.687918e-01</td>\n",
       "      <td>mcnemar</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449708</td>\n",
       "      <td>5q</td>\n",
       "      <td>Llama-3.3-70B-Instruct-Turbo mixedprompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>lit vs fig</td>\n",
       "      <td>Llama-3.1-70B-Instruct cf</td>\n",
       "      <td>0.603516</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>chi2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3.3-70B-Instruct-Turbo m2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>lit vs fig</td>\n",
       "      <td>Llama-3.1-405B-Instruct c</td>\n",
       "      <td>0.808594</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>5.290000e-09</td>\n",
       "      <td>chi2</td>\n",
       "      <td>7m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3-70B-Instruct cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>lit vs fig</td>\n",
       "      <td>Llama-3.1-405B-Instruct cf</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>7.643737e-02</td>\n",
       "      <td>chi2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3.1-70B-Instruct cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>lit vs fig</td>\n",
       "      <td>Llama-3.3-70B-Instruct c</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.636719</td>\n",
       "      <td>6.450000e-10</td>\n",
       "      <td>chi2</td>\n",
       "      <td>7m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3.1-405B-Instruct cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>lit vs fig</td>\n",
       "      <td>Llama-3.3-70B-Instruct cf</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.611328</td>\n",
       "      <td>8.978345e-01</td>\n",
       "      <td>chi2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama-3.3-70B-Instruct cf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               test                       model      avg1      avg2  \\\n",
       "0    model vs human     Llama3.1-70B-Instruct Q  0.913613  0.945852   \n",
       "1    model vs human    Llama3.1-405B-Instruct Q  0.931937  0.945852   \n",
       "2    model vs human     Llama3.3-70B-Instruct Q  0.920593  0.945852   \n",
       "3    model vs human               gpt-4o-mini Q  0.880454  0.945852   \n",
       "4    model vs human                    gpt-4o Q  0.949389  0.945852   \n",
       "..              ...                         ...       ...       ...   \n",
       "216      lit vs fig   Llama-3.1-70B-Instruct cf  0.603516  0.605469   \n",
       "217      lit vs fig   Llama-3.1-405B-Instruct c  0.808594  0.677083   \n",
       "218      lit vs fig  Llama-3.1-405B-Instruct cf  0.679688  0.625000   \n",
       "219      lit vs fig    Llama-3.3-70B-Instruct c  0.781250  0.636719   \n",
       "220      lit vs fig   Llama-3.3-70B-Instruct cf  0.617188  0.611328   \n",
       "\n",
       "           pvalue stattest group  p_corrected corrected test  \\\n",
       "0    1.558171e-03  mcnemar     1     0.126092             5q   \n",
       "1    1.742054e-01  mcnemar     1     0.739841             5q   \n",
       "2    1.127581e-02  mcnemar     1     0.716996             5q   \n",
       "3    2.220000e-09  mcnemar     1     0.126092             5q   \n",
       "4    7.687918e-01  mcnemar     1     0.449708             5q   \n",
       "..            ...      ...   ...          ...            ...   \n",
       "216  1.000000e+00     chi2   NaN          NaN            NaN   \n",
       "217  5.290000e-09     chi2    7m          NaN            NaN   \n",
       "218  7.643737e-02     chi2   NaN          NaN            NaN   \n",
       "219  6.450000e-10     chi2    7m          NaN            NaN   \n",
       "220  8.978345e-01     chi2   NaN          NaN            NaN   \n",
       "\n",
       "                               corrected model  \n",
       "0                       Llama2-70B mixedprompt  \n",
       "1                  Llama2-13B-chat mixedprompt  \n",
       "2     Llama-3.1-70B-Instruct-Turbo mixedprompt  \n",
       "3    Llama-3.1-405B-Instruct-Turbo mixedprompt  \n",
       "4     Llama-3.3-70B-Instruct-Turbo mixedprompt  \n",
       "..                                         ...  \n",
       "216            Llama-3.3-70B-Instruct-Turbo m2  \n",
       "217                    Llama-3-70B-Instruct cf  \n",
       "218                  Llama-3.1-70B-Instruct cf  \n",
       "219                 Llama-3.1-405B-Instruct cf  \n",
       "220                  Llama-3.3-70B-Instruct cf  \n",
       "\n",
       "[221 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple comparisons correction\n",
    "stat_results = pd.read_csv(\"Results Nov25/stats_out_z_02-02-26.csv\")\n",
    "corrected = []\n",
    "ctest = []\n",
    "cmodel = []\n",
    "groups = set(stat_results[\"group\"])\n",
    "groups.discard(np.nan)\n",
    "for t in groups:\n",
    "    corrected += list(multipletests(stat_results[\"pvalue\"][stat_results[\"group\"]==t],method=\"fdr_bh\")[1])\n",
    "    ctest += [t] * len(stat_results[stat_results[\"group\"]==t])\n",
    "    cmodel += list(stat_results[\"model\"][stat_results[\"group\"]==t])\n",
    "\n",
    "t = np.nan\n",
    "corrected += [np.nan] * len(stat_results[stat_results[\"group\"].isna()])\n",
    "ctest += [t] * len(stat_results[stat_results[\"group\"].isna()])\n",
    "cmodel += list(stat_results[\"model\"][stat_results[\"group\"].isna()])\n",
    "    \n",
    "stat_results[\"p_corrected\"] = corrected\n",
    "stat_results[\"corrected test\"] = ctest\n",
    "stat_results[\"corrected model\"] = cmodel\n",
    "\n",
    "stat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca05e66e-db45-4176-b017-c80bb2b4efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_results.to_csv(\"Results Nov25/stats_corrected_bh_02-02-26.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935cf312-bb07-42b8-aaf7-d47f905fef77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
