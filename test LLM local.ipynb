{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085a94ef-6a79-4252-aa1e-4b681df531a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jo16726\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:169: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee10b05-b6d2-4840-b535-67b170b18024",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTNeoForCausalLM.from_pretrained(\"transformers/models--EleutherAI--gpt-neo-1.3B/snapshots/8282180b53cba30a1575e49de1530019e5931739\", local_files_only=True)#.cuda()\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"transformers/models--EleutherAI--gpt-neo-1.3B/snapshots/8282180b53cba30a1575e49de1530019e5931739\", local_files_only=True)\n",
    "modelstr = \"GPT-Neo-1.3B\"\n",
    "\n",
    "#accesstoken = \"\"\n",
    "#model = LlamaForCausalLM.from_pretrained(\"transformers/model-llama2-7B\", local_files_only=True).cuda()\n",
    "#tokenizer = LlamaTokenizer.from_pretrained(\"transformers/model-llama2-7B\", local_files_only=True)\n",
    "#modelstr = \"Llama-2 7B\"\n",
    "\n",
    "#accesstoken = \"\"\n",
    "#model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-hf\", use_auth_token=accesstoken)\n",
    "#tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-hf\", use_auth_token=accesstoken)\n",
    "#modelstr = \"Llama-2 13B\"\n",
    "\n",
    "#model = GPTNeoXForCausalLM.from_pretrained(\"transformers/gpt-neox-20b\", local_files_only=True)#.half().cuda\n",
    "#tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"transformers/gpt-neox-20b\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a294378-213b-4329-839d-e1c91fd3918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_long = pd.read_csv('FIG-QA/Fig-QA Dataset copy.csv')\n",
    "\n",
    "#data_negsample = pd.read_excel('FIG-QA/negsents results/negation sentences.xlsx')\n",
    "#data_negsample_lem = pd.read_csv('FIG-QA/negsents results/negsents_lem.csv')\n",
    "\n",
    "data = data_long\n",
    "data = data[(data.labels!=-1)]\n",
    "#dataname = \"negsents_lem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f55420d-7718-42a2-bd82-e1172c4e846e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 9110\n",
      "256 / 9110\n",
      "512 / 9110\n",
      "768 / 9110\n",
      "1024 / 9110\n",
      "1280 / 9110\n",
      "1536 / 9110\n",
      "1792 / 9110\n",
      "2048 / 9110\n",
      "2304 / 9110\n",
      "2560 / 9110\n",
      "2816 / 9110\n",
      "3072 / 9110\n",
      "3328 / 9110\n",
      "3584 / 9110\n",
      "3840 / 9110\n",
      "4096 / 9110\n",
      "4352 / 9110\n",
      "4608 / 9110\n",
      "4864 / 9110\n",
      "5120 / 9110\n",
      "5376 / 9110\n",
      "5632 / 9110\n",
      "5888 / 9110\n",
      "6144 / 9110\n",
      "6400 / 9110\n",
      "6656 / 9110\n",
      "6912 / 9110\n",
      "7168 / 9110\n",
      "7424 / 9110\n",
      "7680 / 9110\n",
      "7936 / 9110\n",
      "8192 / 9110\n",
      "8448 / 9110\n",
      "8704 / 9110\n",
      "8960 / 9110\n",
      "0.5802414928649835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jo16726\\AppData\\Local\\Temp\\ipykernel_24088\\646748240.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sdata[\"{} 1\".format(modelstr)], sdata[\"{} 2\".format(modelstr)], sdata[\"{} bin\".format(modelstr)] = scores1, scores2, classifications\n",
      "C:\\Users\\jo16726\\AppData\\Local\\Temp\\ipykernel_24088\\646748240.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sdata[\"{} 1\".format(modelstr)], sdata[\"{} 2\".format(modelstr)], sdata[\"{} bin\".format(modelstr)] = scores1, scores2, classifications\n",
      "C:\\Users\\jo16726\\AppData\\Local\\Temp\\ipykernel_24088\\646748240.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sdata[\"{} 1\".format(modelstr)], sdata[\"{} 2\".format(modelstr)], sdata[\"{} bin\".format(modelstr)] = scores1, scores2, classifications\n"
     ]
    }
   ],
   "source": [
    "midphrase =  \" In other words, \" #\" That is to say, \"\n",
    "sdata = data\n",
    "scores1 = []\n",
    "scores2 = []\n",
    "classifications = []\n",
    "\n",
    "for i in range(len(sdata[:])):\n",
    "    # prepare prompt\n",
    "    if sdata.iloc()[i]['startphrase'][-1] == \".\":\n",
    "        prompt1 = (sdata.iloc()[i]['startphrase'] + midphrase + sdata.iloc()[i]['ending1'])\n",
    "    else:\n",
    "        prompt1 = (sdata.iloc()[i]['startphrase'] + \".\" + midphrase + sdata.iloc()[i]['ending1'])\n",
    "    if sdata.iloc()[i]['startphrase'][-1] == \".\":\n",
    "        prompt2 = (sdata.iloc()[i]['startphrase'] + midphrase + sdata.iloc()[i]['ending2'])\n",
    "    else:\n",
    "        prompt2 = (sdata.iloc()[i]['startphrase'] + \".\" + midphrase + sdata.iloc()[i]['ending2'])\n",
    "        \n",
    "    input_ids1 = tokenizer(prompt1, return_tensors=\"pt\").input_ids#.to(\"cuda\")\n",
    "    loss1, logits1 = model(input_ids1, labels=input_ids1)[:2]\n",
    "    input_ids2 = tokenizer(prompt2, return_tensors=\"pt\").input_ids#.to(\"cuda\")\n",
    "    loss2, logits2 = model(input_ids2, labels=input_ids2)[:2]\n",
    "    Pxy1 = math.exp(-1.0 * loss1)\n",
    "    Pxy2 = math.exp(-1.0 * loss2)\n",
    "    P1 = Pxy1/(Pxy1+Pxy2)\n",
    "    P2 = Pxy2/(Pxy1+Pxy2)\n",
    "    scores1.append(P1)\n",
    "    scores2.append(P2)\n",
    "    if sdata.iloc()[i]['labels'] == 0:\n",
    "        if  P1 > P2: \n",
    "            classification = 1\n",
    "        else:\n",
    "            classification = 0\n",
    "    elif sdata.iloc()[i]['labels'] == 1:\n",
    "        if  P2 > P1: \n",
    "            classification = 1\n",
    "        else:\n",
    "            classification = 0\n",
    "    else:\n",
    "        classification = \"\"\n",
    "    classifications.append(classification)\n",
    "    \n",
    "    if i%256 == 0:\n",
    "        print(i,\"/\",len(sdata))\n",
    "        \n",
    "sdata[\"{} 1\".format(modelstr)], sdata[\"{} 2\".format(modelstr)], sdata[\"{} bin\".format(modelstr)] = scores1, scores2, classifications\n",
    "\n",
    "print(np.mean(classifications))\n",
    "sdata.to_csv(\"FIG-QA/test_m2_GPT Neo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995631f-cb1e-450e-9db0-66b832794296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
